{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpl_image_grid(images):\n",
    "    \"\"\"\n",
    "    Create an image grid from an array of images. Show up to 16 images in one figure\n",
    "\n",
    "    Arguments:\n",
    "        image {Torch tensor} -- NxWxH array of images\n",
    "\n",
    "    Returns:\n",
    "        Matplotlib figure\n",
    "    \"\"\"\n",
    "    # Create a figure to contain the plot.\n",
    "    n = min(images.shape[0], 16) # no more than 16 thumbnails\n",
    "    rows = 4\n",
    "    cols = (n // 4) + (1 if (n % 4) != 0 else 0)\n",
    "    figure = plt.figure(figsize=(2*rows, 2*cols))\n",
    "    plt.subplots_adjust(0, 0, 1, 1, 0.001, 0.001)\n",
    "    for i in range(n):\n",
    "        # Start next subplot.\n",
    "        plt.subplot(cols, rows, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        if images.shape[1] == 3:\n",
    "            # this is specifically for 3 softmax'd classes with 0 being bg\n",
    "            # We are building a probability map from our three classes using \n",
    "            # fractional probabilities contained in the mask\n",
    "            vol = images[i].detach().numpy()\n",
    "            img = [[[(1-vol[0,x,y])*vol[1,x,y], (1-vol[0,x,y])*vol[2,x,y], 0] \\\n",
    "                            for y in range(vol.shape[2])] \\\n",
    "                            for x in range(vol.shape[1])]\n",
    "            plt.imshow(img)\n",
    "        else: # plotting only 1st channel\n",
    "            plt.imshow((images[i, 0]*255).int(), cmap= \"gray\")\n",
    "\n",
    "    return figure\n",
    "\n",
    "def log_to_tensorboard(writer, loss, data, target, prediction_softmax, prediction, counter):\n",
    "    \"\"\"Logs data to Tensorboard\n",
    "\n",
    "    Arguments:\n",
    "        writer {SummaryWriter} -- PyTorch Tensorboard wrapper to use for logging\n",
    "        loss {float} -- loss\n",
    "        data {tensor} -- image data\n",
    "        target {tensor} -- ground truth label\n",
    "        prediction_softmax {tensor} -- softmax'd prediction\n",
    "        prediction {tensor} -- raw prediction (to be used in argmax)\n",
    "        counter {int} -- batch and epoch counter\n",
    "    \"\"\"\n",
    "    writer.add_scalar(\"Loss\",\\\n",
    "                    loss, counter)\n",
    "    writer.add_figure(\"Image Data\",\\\n",
    "        mpl_image_grid(data.float().cpu()), global_step=counter)\n",
    "    writer.add_figure(\"Mask\",\\\n",
    "        mpl_image_grid(target.float().cpu()), global_step=counter)\n",
    "    writer.add_figure(\"Probability map\",\\\n",
    "        mpl_image_grid(prediction_softmax.cpu()), global_step=counter)\n",
    "    writer.add_figure(\"Prediction\",\\\n",
    "        mpl_image_grid(torch.argmax(prediction.cpu(), dim=1, keepdim=True)), global_step=counter)\n",
    "\n",
    "def save_numpy_as_image(arr, path):\n",
    "    \"\"\"\n",
    "    This saves image (2D array) as a file using matplotlib\n",
    "\n",
    "    Arguments:\n",
    "        arr {array} -- 2D array of pixels\n",
    "        path {string} -- path to file\n",
    "    \"\"\"\n",
    "    plt.imshow(arr, cmap=\"gray\") #Needs to be in row,col order\n",
    "    plt.savefig(path)\n",
    "\n",
    "def med_reshape(image, new_shape):\n",
    "    \"\"\"\n",
    "    This function reshapes 3D data to new dimension padding with zeros\n",
    "    and leaving the content in the top-left corner\n",
    "\n",
    "    Arguments:\n",
    "        image {array} -- 3D array of pixel data\n",
    "        new_shape {3-tuple} -- expected output shape\n",
    "\n",
    "    Returns:\n",
    "        3D array of desired shape, padded with zeroes\n",
    "    \"\"\"\n",
    "\n",
    "    reshaped_image = np.zeros(new_shape)\n",
    "\n",
    "    # TASK: write your original image into the reshaped image\n",
    "    # <CODE GOES HERE>\n",
    "\n",
    "    return reshaped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## volume_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dice3d(a, b):\n",
    "    \"\"\"\n",
    "    This will compute the Dice Similarity coefficient for two 3-dimensional volumes\n",
    "    Volumes are expected to be of the same size. We are expecting binary masks -\n",
    "    0's are treated as background and anything else is counted as data\n",
    "\n",
    "    Arguments:\n",
    "        a {Numpy array} -- 3D array with first volume\n",
    "        b {Numpy array} -- 3D array with second volume\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    if len(a.shape) != 3 or len(b.shape) != 3:\n",
    "        raise Exception(f\"Expecting 3 dimensional inputs, got {a.shape} and {b.shape}\")\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise Exception(f\"Expecting inputs of the same shape, got {a.shape} and {b.shape}\")\n",
    "\n",
    "    # TASK: Write implementation of Dice3D. If you completed exercises in the lessons\n",
    "    # you should already have it.\n",
    "    # <YOUR CODE HERE>\n",
    "    pass\n",
    "\n",
    "def Jaccard3d(a, b):\n",
    "    \"\"\"\n",
    "    This will compute the Jaccard Similarity coefficient for two 3-dimensional volumes\n",
    "    Volumes are expected to be of the same size. We are expecting binary masks - \n",
    "    0's are treated as background and anything else is counted as data\n",
    "\n",
    "    Arguments:\n",
    "        a {Numpy array} -- 3D array with first volume\n",
    "        b {Numpy array} -- 3D array with second volume\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    if len(a.shape) != 3 or len(b.shape) != 3:\n",
    "        raise Exception(f\"Expecting 3 dimensional inputs, got {a.shape} and {b.shape}\")\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise Exception(f\"Expecting inputs of the same shape, got {a.shape} and {b.shape}\")\n",
    "\n",
    "    # TASK: Write implementation of Jaccard similarity coefficient. Please do not use \n",
    "    # the Dice3D function from above to do the computation ;)\n",
    "    # <YOUR CODE GOES HERE>\n",
    "\n",
    "    return #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HippocampusDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "from medpy.io import load\n",
    "\n",
    "from utils.utils import med_reshape\n",
    "\n",
    "def LoadHippocampusData(root_dir, y_shape, z_shape):\n",
    "    '''\n",
    "    This function loads our dataset form disk into memory,\n",
    "    reshaping output to common size\n",
    "\n",
    "    Arguments:\n",
    "        volume {Numpy array} -- 3D array representing the volume\n",
    "\n",
    "    Returns:\n",
    "        Array of dictionaries with data stored in seg and image fields as \n",
    "        Numpy arrays of shape [AXIAL_WIDTH, Y_SHAPE, Z_SHAPE]\n",
    "    '''\n",
    "\n",
    "    image_dir = os.path.join(root_dir, 'images')\n",
    "    label_dir = os.path.join(root_dir, 'labels')\n",
    "\n",
    "    images = [f for f in listdir(image_dir) if (\n",
    "        isfile(join(image_dir, f)) and f[0] != \".\")]\n",
    "\n",
    "    out = []\n",
    "    for f in images:\n",
    "\n",
    "        # We would benefit from mmap load method here if dataset doesn't fit into memory\n",
    "        # Images are loaded here using MedPy's load method. We will ignore header \n",
    "        # since we will not use it\n",
    "        image, _ = load(os.path.join(image_dir, f))\n",
    "        label, _ = load(os.path.join(label_dir, f))\n",
    "\n",
    "        # TASK: normalize all images (but not labels) so that values are in [0..1] range\n",
    "        # <YOUR CODE GOES HERE>\n",
    "\n",
    "        # We need to reshape data since CNN tensors that represent minibatches\n",
    "        # in our case will be stacks of slices and stacks need to be of the same size.\n",
    "        # In the inference pathway we will need to crop the output to that\n",
    "        # of the input image.\n",
    "        # Note that since we feed individual slices to the CNN, we only need to \n",
    "        # extend 2 dimensions out of 3. We choose to extend coronal and sagittal here\n",
    "\n",
    "        # TASK: med_reshape function is not complete. Go and fix it!\n",
    "        image = med_reshape(image, new_shape=(image.shape[0], y_shape, z_shape))\n",
    "        label = med_reshape(label, new_shape=(label.shape[0], y_shape, z_shape)).astype(int)\n",
    "\n",
    "        # TASK: Why do we need to cast label to int?\n",
    "        # ANSWER: \n",
    "\n",
    "        out.append({\"image\": image, \"seg\": label, \"filename\": f})\n",
    "\n",
    "    # Hippocampus dataset only takes about 300 Mb RAM, so we can afford to keep it all in RAM\n",
    "    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "# self.name = \"Basic_unet\"\n",
    "# self.n_epochs = 10\n",
    "# self.learning_rate = 0.0002\n",
    "# self.batch_size = 8\n",
    "# self.patch_size = 64\n",
    "# self.test_results_dir = \"RESULTS GO HERE\"\n",
    "\n",
    "root_dir = r\"YOUR DIRECTORY HERE\"\n",
    "patch_size = 64\n",
    "\n",
    "# TASK: LoadHippocampusData is not complete. Go to the implementation and complete it. \n",
    "data = LoadHippocampusData(root_dir, y_shape = patch_size, z_shape = patch_size)\n",
    "\n",
    "keys = range(len(data))\n",
    "\n",
    "# Here, random permutation of keys array would be useful in case if we do something like \n",
    "# a k-fold training and combining the results. \n",
    "\n",
    "split = dict()\n",
    "\n",
    "# TASK: create three keys in the dictionary: \"train\", \"val\" and \"test\". In each key, store\n",
    "# the array with indices of training volumes to be used for training, validation \n",
    "# and testing respectively.\n",
    "# <YOUR CODE GOES HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SlicesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SlicesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This class represents an indexable Torch dataset\n",
    "    which could be consumed by the PyTorch DataLoader class\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        self.slices = []\n",
    "\n",
    "        for i, d in enumerate(data):\n",
    "            for j in range(d[\"image\"].shape[0]):\n",
    "                self.slices.append((i, j))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This method is called by PyTorch DataLoader class to return a sample with id idx\n",
    "\n",
    "        Arguments: \n",
    "            idx {int} -- id of sample\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of 2 Torch Tensors of dimensions [1, W, H]\n",
    "        \"\"\"\n",
    "        slc = self.slices[idx]\n",
    "        sample = dict()\n",
    "        sample[\"id\"] = idx\n",
    "\n",
    "        # You could implement caching strategy here if dataset is too large to fit\n",
    "        # in memory entirely\n",
    "        # Also this would be the place to call transforms if data augmentation is used\n",
    "        \n",
    "        # TASK: Create two new keys in the \"sample\" dictionary, named \"image\" and \"seg\"\n",
    "        # The values are 3D Torch Tensors with image and label data respectively. \n",
    "        # First dimension is size 1, and last two hold the voxel data from the respective\n",
    "        # slices. Write code that stores the 2D slice data in the last 2 dimensions of the 3D Tensors. \n",
    "        # Your tensor needs to be of shape [1, patch_size, patch_size]\n",
    "        # Don't forget that you need to put a Torch Tensor into your dictionary element's value\n",
    "        # Hint: your 3D data sits in self.data variable, the id of the 3D volume from data array\n",
    "        # and the slice number are in the slc variable. \n",
    "        # Hint2: You can use None notation like so: arr[None, :] to add size-1 \n",
    "        # dimension to a Numpy array\n",
    "        # <YOUR CODE GOES HERE>\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This method is called by PyTorch DataLoader class to return number of samples in the dataset\n",
    "\n",
    "        Returns:\n",
    "            int\n",
    "        \"\"\"\n",
    "        return len(self.slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes=3, in_channels=1, initial_filter_size=64, kernel_size=3, num_downs=4, norm_layer=nn.InstanceNorm2d):\n",
    "        # norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(in_channels=initial_filter_size * 2 ** (num_downs-1), out_channels=initial_filter_size * 2 ** num_downs,\n",
    "                                             num_classes=num_classes, kernel_size=kernel_size, norm_layer=norm_layer, innermost=True)\n",
    "        for i in range(1, num_downs):\n",
    "            unet_block = UnetSkipConnectionBlock(in_channels=initial_filter_size * 2 ** (num_downs-(i+1)),\n",
    "                                                 out_channels=initial_filter_size * 2 ** (num_downs-i),\n",
    "                                                 num_classes=num_classes, kernel_size=kernel_size, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(in_channels=in_channels, out_channels=initial_filter_size,\n",
    "                                             num_classes=num_classes, kernel_size=kernel_size, submodule=unet_block, norm_layer=norm_layer,\n",
    "                                             outermost=True)\n",
    "\n",
    "        self.model = unet_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Defines the submodule with skip connection.\n",
    "# X -------------------identity---------------------- X\n",
    "#   |-- downsampling -- |submodule| -- upsampling --|\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, in_channels=None, out_channels=None, num_classes=1, kernel_size=3,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.InstanceNorm2d, use_dropout=False):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        # downconv\n",
    "        pool = nn.MaxPool2d(2, stride=2)\n",
    "        conv1 = self.contract(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, norm_layer=norm_layer)\n",
    "        conv2 = self.contract(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, norm_layer=norm_layer)\n",
    "\n",
    "        # upconv\n",
    "        conv3 = self.expand(in_channels=out_channels*2, out_channels=out_channels, kernel_size=kernel_size)\n",
    "        conv4 = self.expand(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size)\n",
    "\n",
    "        if outermost:\n",
    "            final = nn.Conv2d(out_channels, num_classes, kernel_size=1)\n",
    "            down = [conv1, conv2]\n",
    "            up = [conv3, conv4, final]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(in_channels*2, in_channels,\n",
    "                                        kernel_size=2, stride=2)\n",
    "            model = [pool, conv1, conv2, upconv]\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(in_channels*2, in_channels, kernel_size=2, stride=2)\n",
    "\n",
    "            down = [pool, conv1, conv2]\n",
    "            up = [conv3, conv4, upconv]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    @staticmethod\n",
    "    def contract(in_channels, out_channels, kernel_size=3, norm_layer=nn.InstanceNorm2d):\n",
    "        layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=1),\n",
    "            norm_layer(out_channels),\n",
    "            nn.LeakyReLU(inplace=True))\n",
    "        return layer\n",
    "\n",
    "    @staticmethod\n",
    "    def expand(in_channels, out_channels, kernel_size=3):\n",
    "        layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    @staticmethod\n",
    "    def center_crop(layer, target_width, target_height):\n",
    "        batch_size, n_channels, layer_width, layer_height = layer.size()\n",
    "        xy1 = (layer_width - target_width) // 2\n",
    "        xy2 = (layer_height - target_height) // 2\n",
    "        return layer[:, :, xy1:(xy1 + target_width), xy2:(xy2 + target_height)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            crop = self.center_crop(self.model(x), x.size()[2], x.size()[3])\n",
    "            return torch.cat([x, crop], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNetInferenceAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from networks.RecursiveUNet import UNet\n",
    "\n",
    "from utils.utils import med_reshape\n",
    "\n",
    "class UNetInferenceAgent:\n",
    "    \"\"\"\n",
    "    Stores model and parameters and some methods to handle inferencing\n",
    "    \"\"\"\n",
    "    def __init__(self, parameter_file_path='', model=None, device=\"cpu\", patch_size=64):\n",
    "\n",
    "        self.model = model\n",
    "        self.patch_size = patch_size\n",
    "        self.device = device\n",
    "\n",
    "        if model is None:\n",
    "            self.model = UNet(num_classes=3)\n",
    "\n",
    "        if parameter_file_path:\n",
    "            self.model.load_state_dict(torch.load(parameter_file_path, map_location=self.device))\n",
    "\n",
    "        self.model.to(device)\n",
    "\n",
    "    def single_volume_inference_unpadded(self, volume):\n",
    "        \"\"\"\n",
    "        Runs inference on a single volume of arbitrary patch size,\n",
    "        padding it to the conformant size first\n",
    "\n",
    "        Arguments:\n",
    "            volume {Numpy array} -- 3D array representing the volume\n",
    "\n",
    "        Returns:\n",
    "            3D NumPy array with prediction mask\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def single_volume_inference(self, volume):\n",
    "        \"\"\"\n",
    "        Runs inference on a single volume of conformant patch size\n",
    "\n",
    "        Arguments:\n",
    "            volume {Numpy array} -- 3D array representing the volume\n",
    "\n",
    "        Returns:\n",
    "            3D NumPy array with prediction mask\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # Assuming volume is a numpy array of shape [X,Y,Z] and we need to slice X axis\n",
    "        slices = []\n",
    "\n",
    "        # TASK: Write code that will create mask for each slice across the X (0th) dimension. After \n",
    "        # that, put all slices into a 3D Numpy array. You can verify if your method is \n",
    "        # correct by running it on one of the volumes in your training set and comparing \n",
    "        # with the label in 3D Slicer.\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "        return # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNetExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data_prep.SlicesDataset import SlicesDataset\n",
    "from utils.utils import log_to_tensorboard\n",
    "from utils.volume_stats import Dice3d, Jaccard3d\n",
    "from networks.RecursiveUNet import UNet\n",
    "from inference.UNetInferenceAgent import UNetInferenceAgent\n",
    "\n",
    "class UNetExperiment:\n",
    "    \"\"\"\n",
    "    This class implements the basic life cycle for a segmentation task with UNet(https://arxiv.org/abs/1505.04597).\n",
    "    The basic life cycle of a UNetExperiment is:\n",
    "\n",
    "        run():\n",
    "            for epoch in n_epochs:\n",
    "                train()\n",
    "                validate()\n",
    "        test()\n",
    "    \"\"\"\n",
    "    def __init__(self, config, split, dataset):\n",
    "        self.n_epochs = config.n_epochs\n",
    "        self.split = split\n",
    "        self._time_start = \"\"\n",
    "        self._time_end = \"\"\n",
    "        self.epoch = 0\n",
    "        self.name = config.name\n",
    "\n",
    "        # Create output folders\n",
    "        dirname = f'{time.strftime(\"%Y-%m-%d_%H%M\", time.gmtime())}_{self.name}'\n",
    "        self.out_dir = os.path.join(config.test_results_dir, dirname)\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "\n",
    "        # Create data loaders\n",
    "        # TASK: SlicesDataset class is not complete. Go to the file and complete it. \n",
    "        # Note that we are using a 2D version of UNet here, which means that it will expect\n",
    "        # batches of 2D slices.\n",
    "        self.train_loader = DataLoader(SlicesDataset(dataset[split[\"train\"]]),\n",
    "                batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "        self.val_loader = DataLoader(SlicesDataset(dataset[split[\"val\"]]),\n",
    "                batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "        # we will access volumes directly for testing\n",
    "        self.test_data = dataset[split[\"test\"]]\n",
    "\n",
    "        # Do we have CUDA available?\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"WARNING: No CUDA device is found. This may take significantly longer!\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Configure our model and other training implements\n",
    "        # We will use a recursive UNet model from German Cancer Research Center, \n",
    "        # Division of Medical Image Computing. It is quite complicated and works \n",
    "        # very well on this task. Feel free to explore it or plug in your own model\n",
    "        self.model = UNet(num_classes=3)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # We are using a standard cross-entropy loss since the model output is essentially\n",
    "        # a tensor with softmax'd prediction of each pixel's probability of belonging \n",
    "        # to a certain class\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # We are using standard SGD method to optimize our weights\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=config.learning_rate)\n",
    "        # Scheduler helps us update learning rate automatically\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
    "\n",
    "        # Set up Tensorboard. By default it saves data into runs folder. You need to launch\n",
    "        self.tensorboard_train_writer = SummaryWriter(comment=\"_train\")\n",
    "        self.tensorboard_val_writer = SummaryWriter(comment=\"_val\")\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        This method is executed once per epoch and takes \n",
    "        care of model weight update cycle\n",
    "        \"\"\"\n",
    "        print(f\"Training epoch {self.epoch}...\")\n",
    "        self.model.train()\n",
    "\n",
    "        # Loop over our minibatches\n",
    "        for i, batch in enumerate(self.train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # TASK: You have your data in batch variable. Put the slices as 4D Torch Tensors of \n",
    "            # shape [BATCH_SIZE, 1, PATCH_SIZE, PATCH_SIZE] into variables data and target. \n",
    "            # Feed data to the model and feed target to the loss function\n",
    "            # \n",
    "            # data = <YOUR CODE HERE>\n",
    "            # target = <YOUR CODE HERE>\n",
    "\n",
    "            prediction = self.model(data)\n",
    "\n",
    "            # We are also getting softmax'd version of prediction to output a probability map\n",
    "            # so that we can see how the model converges to the solution\n",
    "            prediction_softmax = F.softmax(prediction, dim=1)\n",
    "\n",
    "            loss = self.loss_function(prediction, target[:, 0, :, :])\n",
    "\n",
    "            # TASK: What does each dimension of variable prediction represent?\n",
    "            # ANSWER:\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if (i % 10) == 0:\n",
    "                # Output to console on every 10th batch\n",
    "                print(f\"\\nEpoch: {self.epoch} Train loss: {loss}, {100*(i+1)/len(self.train_loader):.1f}% complete\")\n",
    "\n",
    "                counter = 100*self.epoch + 100*(i/len(self.train_loader))\n",
    "\n",
    "                # You don't need to do anything with this function, but you are welcome to \n",
    "                # check it out if you want to see how images are logged to Tensorboard\n",
    "                # or if you want to output additional debug data\n",
    "                log_to_tensorboard(\n",
    "                    self.tensorboard_train_writer,\n",
    "                    loss,\n",
    "                    data,\n",
    "                    target,\n",
    "                    prediction_softmax,\n",
    "                    prediction,\n",
    "                    counter)\n",
    "\n",
    "            print(\".\", end='')\n",
    "\n",
    "        print(\"\\nTraining complete\")\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"\n",
    "        This method runs validation cycle, using same metrics as \n",
    "        Train method. Note that model needs to be switched to eval\n",
    "        mode and no_grad needs to be called so that gradients do not \n",
    "        propagate\n",
    "        \"\"\"\n",
    "        print(f\"Validating epoch {self.epoch}...\")\n",
    "\n",
    "        # Turn off gradient accumulation by switching model to \"eval\" mode\n",
    "        self.model.eval()\n",
    "        loss_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(self.val_loader):\n",
    "                \n",
    "                # TASK: Write validation code that will compute loss on a validation sample\n",
    "                # <YOUR CODE HERE>\n",
    "\n",
    "                print(f\"Batch {i}. Data shape {data.shape} Loss {loss}\")\n",
    "\n",
    "                # We report loss that is accumulated across all of validation set\n",
    "                loss_list.append(loss.item())\n",
    "\n",
    "        self.scheduler.step(np.mean(loss_list))\n",
    "\n",
    "        log_to_tensorboard(\n",
    "            self.tensorboard_val_writer,\n",
    "            np.mean(loss_list),\n",
    "            data,\n",
    "            target,\n",
    "            prediction_softmax, \n",
    "            prediction,\n",
    "            (self.epoch+1) * 100)\n",
    "        print(f\"Validation complete\")\n",
    "\n",
    "    def save_model_parameters(self):\n",
    "        \"\"\"\n",
    "        Saves model parameters to a file in results directory\n",
    "        \"\"\"\n",
    "        path = os.path.join(self.out_dir, \"model.pth\")\n",
    "\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    def load_model_parameters(self, path=''):\n",
    "        \"\"\"\n",
    "        Loads model parameters from a supplied path or a\n",
    "        results directory\n",
    "        \"\"\"\n",
    "        if not path:\n",
    "            model_path = os.path.join(self.out_dir, \"model.pth\")\n",
    "        else:\n",
    "            model_path = path\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "        else:\n",
    "            raise Exception(f\"Could not find path {model_path}\")\n",
    "\n",
    "    def run_test(self):\n",
    "        \"\"\"\n",
    "        This runs test cycle on the test dataset.\n",
    "        Note that process and evaluations are quite different\n",
    "        Here we are computing a lot more metrics and returning\n",
    "        a dictionary that could later be persisted as JSON\n",
    "        \"\"\"\n",
    "        print(\"Testing...\")\n",
    "        self.model.eval()\n",
    "\n",
    "        # In this method we will be computing metrics that are relevant to the task of 3D volume\n",
    "        # segmentation. Therefore, unlike train and validation methods, we will do inferences\n",
    "        # on full 3D volumes, much like we will be doing it when we deploy the model in the \n",
    "        # clinical environment. \n",
    "\n",
    "        # TASK: Inference Agent is not complete. Go and finish it. Feel free to test the class\n",
    "        # in a module of your own by running it against one of the data samples\n",
    "        inference_agent = UNetInferenceAgent(model=self.model, device=self.device)\n",
    "\n",
    "        out_dict = {}\n",
    "        out_dict[\"volume_stats\"] = []\n",
    "        dc_list = []\n",
    "        jc_list = []\n",
    "\n",
    "        # for every in test set\n",
    "        for i, x in enumerate(self.test_data):\n",
    "            pred_label = inference_agent.single_volume_inference(x[\"image\"])\n",
    "\n",
    "            # We compute and report Dice and Jaccard similarity coefficients which \n",
    "            # assess how close our volumes are to each other\n",
    "\n",
    "            # TASK: Dice3D and Jaccard3D functions are not implemented. \n",
    "            #  Complete the implementation as we discussed\n",
    "            # in one of the course lessons, you can look up definition of Jaccard index \n",
    "            # on Wikipedia. If you completed it\n",
    "            # correctly (and if you picked your train/val/test split right ;)),\n",
    "            # your average Jaccard on your test set should be around 0.80\n",
    "\n",
    "            dc = Dice3d(pred_label, x[\"seg\"])\n",
    "            jc = Jaccard3d(pred_label, x[\"seg\"])\n",
    "            dc_list.append(dc)\n",
    "            jc_list.append(jc)\n",
    "\n",
    "            # STAND-OUT SUGGESTION: By way of exercise, consider also outputting:\n",
    "            # * Sensitivity and specificity (and explain semantic meaning in terms of \n",
    "            #   under/over segmenting)\n",
    "            # * Dice-per-slice and render combined slices with lowest and highest DpS\n",
    "            # * Dice per class (anterior/posterior)\n",
    "\n",
    "            out_dict[\"volume_stats\"].append({\n",
    "                \"filename\": x['filename'],\n",
    "                \"dice\": dc,\n",
    "                \"jaccard\": jc\n",
    "                })\n",
    "            print(f\"{x['filename']} Dice {dc:.4f}. {100*(i+1)/len(self.test_data):.2f}% complete\")\n",
    "\n",
    "        out_dict[\"overall\"] = {\n",
    "            \"mean_dice\": np.mean(dc_list),\n",
    "            \"mean_jaccard\": np.mean(jc_list)}\n",
    "\n",
    "        print(\"\\nTesting complete.\")\n",
    "        return out_dict\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Kicks off train cycle and writes model parameter file at the end\n",
    "        \"\"\"\n",
    "        self._time_start = time.time()\n",
    "\n",
    "        print(\"Experiment started.\")\n",
    "\n",
    "        # Iterate over epochs\n",
    "        for self.epoch in range(self.n_epochs):\n",
    "            self.train()\n",
    "            self.validate()\n",
    "\n",
    "        # save model for inferencing\n",
    "        self.save_model_parameters()\n",
    "\n",
    "        self._time_end = time.time()\n",
    "        print(f\"Run complete. Total time: {time.strftime('%H:%M:%S', time.gmtime(self._time_end - self._time_start))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and run experiment\n",
    "\n",
    "# TASK: Class UNetExperiment has missing pieces. Go to the file and fill them in\n",
    "exp = UNetExperiment(c, split, data)\n",
    "\n",
    "# You could free up memory by deleting the dataset\n",
    "# as it has been copied into loaders\n",
    "# del dataset \n",
    "\n",
    "# run training\n",
    "exp.run()\n",
    "\n",
    "# prep and run testing\n",
    "\n",
    "# TASK: Test method is not complete. Go to the method and complete it\n",
    "results_json = exp.run_test()\n",
    "\n",
    "results_json[\"config\"] = vars(c)\n",
    "\n",
    "with open(os.path.join(exp.out_dir, \"results.json\"), 'w') as out_file:\n",
    "    json.dump(results_json, out_file, indent=2, separators=(',', ': '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
